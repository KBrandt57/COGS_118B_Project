{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d963385-90e8-4332-9d3e-d4b620e8343c",
   "metadata": {},
   "source": [
    "# Can you find a better way to segment your customers?\n",
    "\n",
    "## üìñ Motivation (Kyra) \n",
    "You work for a medical device manufacturer in Switzerland. Your company manufactures orthopedic devices and sells them worldwide. The company sells directly to individual doctors who use them on rehabilitation and physical therapy patients.\n",
    "\n",
    "Historically, the sales and customer support departments have grouped doctors by geography. However, the region is not a good predictor of the number of purchases a doctor will make or their support needs.\n",
    "\n",
    "Your team wants to use a data-centric approach to segmenting doctors to improve marketing, customer service, and product planning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1b63c-61ed-4e21-85e9-a3644a878c83",
   "metadata": {},
   "source": [
    "## Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d64e5fc-e7e5-4461-89ad-3ade63270f52",
   "metadata": {},
   "source": [
    "The goal of our project is to perform cluster analysis. Since our project uses K-means algorithm as our primary clustering technique, one non-negligible issue with this algorithm is the curse of dimensionality. In other words, when we run K-means algorithm with a large amount of features, then the algorithm is not likely to perform well due to the exponentially increasing vector space. \n",
    "\n",
    "One solution to combat the curse of dimensionality is to apply dimensionality reduction on our feature space. Research by Sidharth Mishra published in 2017 proposes the method \"Principal Component Analysis\" (1). In a nutshell, the method finds the orthogonal components which explains the most variance of the projected data. The dimensionality reduction kicks in when we select the first few components that explain the most variance, and discard the last few components that don't explain much variance.\n",
    "\n",
    "While PCA is a great method, it is a linear dimensionality reduction, which limits its capacity to transform the data that are not linearly separable. Thus we take a step further to apply nonlinear dimensionality reduction technique. The technique we pick is called \"Radial Basis Function PCA\", in which a kernel function is applied to our data to make our data separable. The idea behind the kernel function is to project our data to higher dimension where it becomes separable. This technique of applying RBF kernel on PCA has shown to increase accuracy of Self Organizing Map (2).\n",
    "\n",
    "<br>\n",
    "\n",
    "Citation: <br>\n",
    "(1) Mishra, Sidharth & Sarkar, Uttam & Taraphder, Subhash & Datta, Sanjoy & Swain, Devi & Saikhom, Reshma & Panda, Sasmita & Laishram, Menalsh. (2017). Principal Component Analysis. International Journal of Livestock Research. 1. 10.5455/ijlr.20170415115235. \n",
    "<br>\n",
    "(2) Roy, Parthajit and Swati Adhikari. ‚ÄúRadial Basis Function based Self-Organizing Map Model for Clustering Spatial Data using PCA.‚Äù (2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0627fd-bcf3-44bc-9d4c-cdcddcdf6fd7",
   "metadata": {},
   "source": [
    "## Methods\n",
    "* ...\n",
    "* Impute the data:\n",
    "    * For satisfaction, since there is only about 30% of the data missing, we use KNN imputer to keep the distribution similar\n",
    "    * For complaints and orders, we assume that if the data is not provided, then the doctor has not filed a complaint or made an order from us\n",
    "* Cluster the data:\n",
    "    * First use RBF PCA to prevent curse of dimensionality mentioned in related work\n",
    "    * Use elbow methods to figure out optimal number of pc components and number of clusters\n",
    "* Explain feature importance:\n",
    "    * Extract pc1 of each clusters and looks at each feature's explained variance ratio\n",
    "    * Perform OLS to see which feature most responsible for purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54d3-5eba-4376-b104-64b8a80f251e",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9f7ef-c29f-4fef-9b33-f4401a3552ee",
   "metadata": {},
   "source": [
    "### Region ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d35db1-28a6-4a13-9941-0788dac88e67",
   "metadata": {},
   "source": [
    "### Purchase and Complaints relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f60c900-f2d8-4038-8cd7-0e540c3f6b7b",
   "metadata": {},
   "source": [
    "## New Customer Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c7bb3-cd82-476d-a66b-c88c9035be9e",
   "metadata": {},
   "source": [
    "Use google doc table to answer: Why should we cherish them?, In what areas do they need more support from us? How can we make them happier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c024bf8-ed2a-435f-b556-1d8e277145d2",
   "metadata": {},
   "source": [
    "What's their general characteristic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e3c21-5f10-4290-85da-937b6106f198",
   "metadata": {},
   "source": [
    "What's their general characteristic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a856679-e3e5-4f45-9751-3f5ebab10f81",
   "metadata": {},
   "source": [
    "<img src=\"images/feature_importance.PNG\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35889f40-d621-4b88-a294-01025254b2d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f8d44-5fde-4b92-bb10-7d45edb88f73",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Cleaning & Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e982f-21ea-4d49-bec2-5620102fbab5",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2812224-1841-4655-b00f-dde1da311ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import KernelPCA, PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7d673-1145-46dc-b7d6-2474722cc6c9",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41117807-d3fc-477e-b80d-0ed0d2d8feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in all four at once\n",
    "doctors = pd.read_csv('data/doctors.csv')\n",
    "orders = pd.read_csv('data/orders.csv')\n",
    "complaints = pd.read_csv('data/complaints.csv')\n",
    "instructions = pd.read_csv('data/instructions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6186b324-afe7-41f2-8de6-d5bc7811f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_satisfaction(sat):\n",
    "    if sat == '--':\n",
    "        sat = np.nan\n",
    "    else:\n",
    "        sat = float(sat)\n",
    "    return sat\n",
    "\n",
    "doctors['Satisfaction'] = doctors['Satisfaction'].apply(clean_satisfaction)\n",
    "\n",
    "def transform_rank(rank):\n",
    "    ###Takes name of doctor's rank and transforms it into ordinal data from 1-9\n",
    "    if rank == 'Ambassador':\n",
    "        num_rank = 9\n",
    "    elif rank == 'Titanium Plus':\n",
    "        num_rank = 8\n",
    "    elif rank == 'Titanium':\n",
    "        num_rank = 7\n",
    "    elif rank == 'Platinum Plus':\n",
    "        num_rank = 6\n",
    "    elif rank == 'Platinum':\n",
    "        num_rank = 5\n",
    "    elif rank == 'Gold Plus':\n",
    "        num_rank = 4\n",
    "    elif rank == 'Gold':\n",
    "        num_rank = 3\n",
    "    elif rank == 'Silver Plus':\n",
    "        num_rank = 2\n",
    "    elif rank == 'Silver':\n",
    "        num_rank = 1\n",
    "    else:\n",
    "        num_rank = np.nan\n",
    "    return num_rank\n",
    "\n",
    "def conv_cat_to_num(cat):\n",
    "    ###Takes category of doctor and returns 1 if specialist and 0 if GP\n",
    "    if cat == 'Specialist':\n",
    "        cat = 1\n",
    "    elif cat == 'General Practitioner':\n",
    "        cat = 0\n",
    "    else:\n",
    "        cat = np.nan\n",
    "    return cat\n",
    "\n",
    "#apply to doctors dataframe\n",
    "doctors['Rank'] = doctors['Rank'].apply(transform_rank)\n",
    "doctors['Category'] = doctors['Category'].apply(conv_cat_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faec8f87-88df-4005-8bce-b75819361744",
   "metadata": {},
   "outputs": [],
   "source": [
    "ords_per_doc = orders['DoctorID'].value_counts()\n",
    "ords_per_doc = pd.DataFrame(ords_per_doc)\n",
    "ords_per_doc.index.name = 'DoctorID'\n",
    "ords_per_doc.columns = ['Orders']\n",
    "ords_per_doc.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe1fc0ca-4ab2-4b53-85b4-07d50f812587",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_IDs = complaints['DoctorID'].unique()\n",
    "doc_IDs = list(doc_IDs)\n",
    "comp_per_doc = pd.DataFrame(doc_IDs)\n",
    "comp_per_doc.columns = ['DoctorID']\n",
    "comp_per_doc['Total Complaints'] = 0\n",
    "\n",
    "for ID in doc_IDs:\n",
    "    temp_df = complaints[complaints['DoctorID'] == ID]\n",
    "    total_comp = temp_df['Qty'].sum()\n",
    "    index = comp_per_doc.index[comp_per_doc['DoctorID'] == ID].tolist()[0]\n",
    "    comp_per_doc.iloc[index, 1] = total_comp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0a9a1a-6b2a-4a7e-baf6-dfb1114d8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instr_conv_to_number(str_in):\n",
    "    if str_in == 'Yes':\n",
    "        result = 1\n",
    "    elif str_in == 'No':\n",
    "        result = 0\n",
    "    else:\n",
    "        result = np.nan\n",
    "    return result\n",
    "\n",
    "instructions['Instructions'] = instructions['Instructions'].apply(instr_conv_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70f998ce-4908-4ea1-b338-aa751b1d7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_merged = doctors.merge(comp_per_doc, how = 'left', on = 'DoctorID')\n",
    "doc_merged = doc_merged.merge(ords_per_doc, how = 'left', on = 'DoctorID')\n",
    "doc_merged = doc_merged.merge(instructions, how = 'left', on = 'DoctorID')\n",
    "\n",
    "doc_merged = doc_merged [['DoctorID',\n",
    "                          'Satisfaction', \n",
    "                          'Category', \n",
    "                          'Incidence rate', \n",
    "                          'R rate', \n",
    "                          'Experience', \n",
    "                          'Purchases', \n",
    "                          'Total Complaints', \n",
    "                          'Orders', \n",
    "                          'Instructions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "901f25bc-7fde-4fd8-8757-93386d81fee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DoctorID</th>\n",
       "      <th>Satisfaction</th>\n",
       "      <th>Category</th>\n",
       "      <th>Incidence rate</th>\n",
       "      <th>R rate</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Purchases</th>\n",
       "      <th>Total Complaints</th>\n",
       "      <th>Orders</th>\n",
       "      <th>Instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AHDCBA</td>\n",
       "      <td>53.85</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.20</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABHAHF</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDHFJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BJJHCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.48</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FJBEA</td>\n",
       "      <td>76.79</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.75</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DoctorID  Satisfaction  Category  Incidence rate  R rate  Experience  \\\n",
       "0   AHDCBA         53.85         1            49.0    0.90        1.20   \n",
       "1   ABHAHF        100.00         0            37.0    0.00        0.00   \n",
       "2    FDHFJ           NaN         1            33.0    1.53        0.00   \n",
       "3   BJJHCA           NaN         1            28.0    2.03        0.48   \n",
       "4    FJBEA         76.79         1            23.0    0.96        0.75   \n",
       "\n",
       "   Purchases  Total Complaints  Orders  Instructions  \n",
       "0       49.0               NaN     NaN           1.0  \n",
       "1       38.0               NaN     NaN           NaN  \n",
       "2       34.0               NaN     NaN           NaN  \n",
       "3       29.0               NaN     NaN           NaN  \n",
       "4       24.0               NaN     NaN           NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367012a-85cd-4179-b217-72417fe90074",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fec93c9c-ba4c-4921-a7bb-94225f45c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = doc_merged.drop(['DoctorID', 'Instructions'], axis=1)\n",
    "df['Total Complaints'] = df['Total Complaints'].fillna(0)\n",
    "df['Orders'] = df['Orders'].fillna(0)\n",
    "df['Satisfaction'] = KNNImputer(n_neighbors=4).fit_transform(np.array(df['Satisfaction'])[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed18225-bd3c-4248-8188-aacd70b1accb",
   "metadata": {},
   "source": [
    "### Transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da233dfc-8077-47d5-b3fc-de134ab11a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, input_array, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, input_array, y=None):\n",
    "        return input_array*1\n",
    "\n",
    "scaled_pipeline = Pipeline([\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "identity_pipeline = Pipeline([\n",
    "        ('identity', IdentityTransformer()),\n",
    "    ])\n",
    "scaler = ColumnTransformer([\n",
    "        ('scaled', scaled_pipeline, [\"Satisfaction\", \"Incidence rate\", \"R rate\", \"Purchases\", \"Total Complaints\", \"Orders\"]),\n",
    "        ('identity', identity_pipeline, [\"Experience\", \"Category\"]),\n",
    "    ])  # transform columnwise and feature is on 2nd dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f151a4-56c2-4b77-9aba-180b11581fe9",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7cba106-3447-45fc-8b04-a553c8d158cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = KernelPCA(n_components=3, random_state=22, kernel='rbf')\n",
    "km = KMeans(n_clusters=3, init=\"k-means++\", n_init=50, max_iter=500, random_state=22)\n",
    "clusterer = Pipeline([\n",
    "           ('scaler', scaler),\n",
    "           ('pca', pca),\n",
    "           ('kmeans', km)])\n",
    "_ = clusterer.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b1e40c-2907-4ae8-be42-760f71bd3191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Satisfaction</th>\n",
       "      <th>Category</th>\n",
       "      <th>Incidence rate</th>\n",
       "      <th>R rate</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Purchases</th>\n",
       "      <th>Total Complaints</th>\n",
       "      <th>Orders</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.85000</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.20</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.21872</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.21872</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.48</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.79000</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.75</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Satisfaction  Category  Incidence rate  R rate  Experience  Purchases  \\\n",
       "0      53.85000         1            49.0    0.90        1.20       49.0   \n",
       "1     100.00000         0            37.0    0.00        0.00       38.0   \n",
       "2      29.21872         1            33.0    1.53        0.00       34.0   \n",
       "3      29.21872         1            28.0    2.03        0.48       29.0   \n",
       "4      76.79000         1            23.0    0.96        0.75       24.0   \n",
       "\n",
       "   Total Complaints  Orders  Cluster  \n",
       "0               0.0     0.0        0  \n",
       "1               0.0     0.0        0  \n",
       "2               0.0     0.0        0  \n",
       "3               0.0     0.0        0  \n",
       "4               0.0     0.0        0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_df = df.copy().assign(Cluster=clusterer['kmeans'].labels_)\n",
    "cluster_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
