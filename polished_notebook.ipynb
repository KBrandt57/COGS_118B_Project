{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d963385-90e8-4332-9d3e-d4b620e8343c",
   "metadata": {},
   "source": [
    "# Customer Segmentation with Clustering Analysis\n",
    "\n",
    "## Motivation \n",
    "We chose a simulated customer segmentation problem for our project. Our simulated client is a Swiss medical device manufacturer who sells orthopedic devices worldwide. Company representatives work directly with individual doctors. According to the given scenario, the sales and customer support departments have historically grouped doctors according to their geographical region. However, as shown later, the region is not the best predictor of the number of purchases a doctor will make or their support needs. \n",
    "\n",
    "We aim to use a data-centric approach, more specifically K-means clustering and dimensionality reduction, to better divide doctors into specific segments and develop spefically targeted approaches to improve marketing, customer service and product planning to each segment. We believe this will increase sales while making the sales and customer service departments more efficient, thus generating more profit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1b63c-61ed-4e21-85e9-a3644a878c83",
   "metadata": {},
   "source": [
    "## Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d64e5fc-e7e5-4461-89ad-3ade63270f52",
   "metadata": {},
   "source": [
    "The goal of our project is to perform cluster analysis. Since our project uses K-means algorithm as our primary clustering technique, one non-negligible issue with this algorithm is the curse of dimensionality. In other words, when we run K-means algorithm with a large amount of features, then the algorithm is not likely to perform well due to the exponentially increasing vector space. \n",
    "\n",
    "One solution to combat the curse of dimensionality is to apply dimensionality reduction on our feature space. Research by Sidharth Mishra published in 2017 discusses the method \"Principal Component Analysis\" (1). In a nutshell, the method finds the orthogonal components which explains the most variance of the projected data. The dimensionality reduction kicks in when we select the first few components that explain the most variance, and discard the last few components that don't explain much variance.\n",
    "\n",
    "While PCA is a great method, it is a linear dimensionality reduction, which limits its capacity to transform the data that are not linearly separable. Thus we take a step further to apply nonlinear dimensionality reduction technique. The technique we pick is called \"Radial Basis Function PCA\", in which a kernel function is applied to our data to make our data separable. The idea behind the kernel function is to project our data to higher dimension where it becomes separable. This technique of applying RBF kernel on PCA has shown to increase accuracy of Self Organizing Map (2).\n",
    "\n",
    "<br>\n",
    "\n",
    "Citation: <br>\n",
    "(1) Mishra, Sidharth & Sarkar, Uttam & Taraphder, Subhash & Datta, Sanjoy & Swain, Devi & Saikhom, Reshma & Panda, Sasmita & Laishram, Menalsh. (2017). Principal Component Analysis. International Journal of Livestock Research. 1. 10.5455/ijlr.20170415115235. \n",
    "<br>\n",
    "(2) Roy, Parthajit and Swati Adhikari. “Radial Basis Function based Self-Organizing Map Model for Clustering Spatial Data using PCA.” (2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0627fd-bcf3-44bc-9d4c-cdcddcdf6fd7",
   "metadata": {},
   "source": [
    "## Methods\n",
    "* Clean and wrangle the data:\n",
    "    * Convert '--' entries in satisfaction column to np.nan\n",
    "    * Total up complaints per doctor from complaints dataframe and add to doctors dataframe\n",
    "    * Total up orders per doctor from orders dataframe and add to doctors dataframe\n",
    "    * Standardize category and instructions in doctors dataframe\n",
    "* Exploratory data analysis:\n",
    "    * Invesitgate relationship between total doctors in region and total purchases for region\n",
    "    * Investigate relationshpi between number of complaints and doctor purchases\n",
    "    * Determine primary variables to be passed on to clustering\n",
    "* Impute the data:\n",
    "    * For satisfaction, since there is only about 30% of the data missing, we use KNN imputer to keep the distribution similar\n",
    "    * For complaints and orders, we assume that if the data is not provided, then the doctor has not filed a complaint or made an order from us\n",
    "* Cluster the data:\n",
    "    * First use RBF PCA to prevent curse of dimensionality mentioned in related work\n",
    "    * Use elbow methods to figure out optimal number of pc components and number of clusters\n",
    "* Explain feature importance:\n",
    "    * Extract pc1 of each clusters and looks at each feature's explained variance ratio\n",
    "    * Perform OLS to see which feature most responsible for purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a60a9ed-99f5-4b7e-927b-0f6a5fdba6c6",
   "metadata": {},
   "source": [
    "### Explanation of Variables in the Data\n",
    "We are given four different dataframes: doctors, orders, complaints and instructions. All four contain an identifying column, \"DoctorID\", that matches the others. \n",
    "\n",
    "**doctors dataframe** - The doctors dataframe forms the basis of our final merged dataframe and contains variables such as the region the doctor works in (\"Region\"), whether the doctor is a specialist or general practitioner (\"Category\"), the doctor's satisfaction and experience with the company (\"Satisfaction\", \"Experience\") as well as their purchases over the last year (\"Purchases\"). This dataframe also contains information on the doctor's incidence rates and re-work rates (\"Incidence rate\", \"R rate\"). Since the company manufacturers medical devices, incidence rate refers to the rate at which they order devices from our company out of their total patients that would require devices such as ours. The re-work rate is the number of re-worked devices (devices that had to be adjusted, repaired or otherwise corrected) divided the total number of devices manufactured. \n",
    "\n",
    "**orders dataframe** - The orders dataframe contains an entry for each new order received by the company, including the order number and the settings of each device ordered. The data on settings was so sparse it could not be fruitfully analyzed. We totaled up the number of orders for each doctor and joined it to the doctors dataframe.\n",
    "\n",
    "**complaints dataframe** - The complaints dataframe lists the quantity of complaints according to doctor and complaint type. We totaled up the number of complaints for each doctor and joined it to the doctors dataframe. We totaled up complaints of each type for each doctor, but again this data was sparse.\n",
    "\n",
    "**instructions dataframe** - The instruction dataframe shows whether the doctor includes special instructions with their orders. We changed each 'yes' entry to 1 and each 'no' entry to 0 before joining it to the doctors dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54d3-5eba-4376-b104-64b8a80f251e",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9f7ef-c29f-4fef-9b33-f4401a3552ee",
   "metadata": {},
   "source": [
    "### Region\n",
    "Since the company has traditionally relied on region to cluster doctors, we first investigated the relationship between region and purchases. This was undertaken by totaling up the number of doctors in each region and then totaling up the purchases of each doctor in that region. We were then able to take the mean of each of these columns to find that there are, on average, 9.5 doctors per region and 102.5 purchases per region.\n",
    "<img src = 'images/Distributions.png'>\n",
    "\n",
    "When the distributions for both total doctors per region and total purchases per region were visualized, there was a visible right skew in both distributions. Therefore, when we investigated linear relationships between the two distributions we applied a log10 transformation. Using ordinary least squares, we found a correlation of about .915, suggesting a very strong positive correlation between the total number of purchases and the total number of doctors in a region. It should be noted however, the middling R-squared value (.623) indicates that only about 2/3 of the variance in total purchases is due to variation in the total number of doctors, and while it does seem to be true that the regions with the most doctors yield the most purchases, this is more a measure of doctor density than a strategic data-driven approach based on the individual doctors themselves. Finding a more targeted approach at the individual level should help all regions yeild more purchases.\n",
    "\n",
    "<img src = 'images/lmplot.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d35db1-28a6-4a13-9941-0788dac88e67",
   "metadata": {},
   "source": [
    "### Relationship between Purchases and Complaints\n",
    "There is no obvious pattern between the total number of complaints per doctor and either their current orders or their previous purchases. \n",
    "<img src = 'images/scatter.png'>\n",
    "However, we would expect complaints to have some sort of relationship with how doctors order from our company, especially as it appears to play a factor in the features of our clustering. Looking a little deeper at the complaints, we can see that a little more than 16% of the doctors in our data have filed a complaint and that around 55% of complaints were filed correctly (meaning the company was actually at fault). \n",
    "\n",
    "Of the doctors who have filed a complaint, 90% are specialists and about 97% of all complaints filed were filed by specialists. 84% of the doctors are specialists overall, so this doesn't seem to be that unexpected of a result. However, 18% of specialists have filed complaints, while only 10% of general practitioners have filed complaints. Of the 9 complaints that were filed by general practioners, 44% were correct and 33% were incorrect, while among the 257 complaints filed by specialists 55% were correct and about 25% were incorrect. Additionally, the mean of total complaints for specialists was close to 4, while the mean total complaints for general practitioners was close to 1. More data would be required to determine if any of these observations are representative of more meaningful trends.\n",
    "\n",
    "<img src = 'images/count.png'>\n",
    "\n",
    "It might also be worth noting that of the 74 doctors who have submitted current orders, 100% have submitted complaints. This may indicate that there is something wrong with this year's products. While we continue with our analysis, this factor should be investigated by the company to ensure quality product is being delivered to the client.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f60c900-f2d8-4038-8cd7-0e540c3f6b7b",
   "metadata": {},
   "source": [
    "## New Customer Segmentation\n",
    " The number of clusters and amount of principal components are determined with the elbow method covered in `eda_notebook.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c9b030-a6e9-4146-a359-4667abea8239",
   "metadata": {},
   "source": [
    "1) The figure below shows the feature mean of each of the cluster. <br>\n",
    "<img src=\"images/feature.PNG\" > <br>\n",
    "Note: there are 121 Unsatisfied Big Players, 140 Veteran Specialists, and 176 Impressed Newcomers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c73e9-423d-4897-bccc-665be6f5cdb3",
   "metadata": {},
   "source": [
    "2) The figure below shows the p-values of the correlation coefficients of each feature against the current purchases for each of the cluster. <br>\n",
    "<img src=\"images/pvalue.PNG\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a902a2-9631-4d22-b52a-80c6383d51f0",
   "metadata": {},
   "source": [
    "3) The figure below shows the correlation coefficients of each feature against the current purchases for each of the cluster. <br>\n",
    "   <img src=\"images/coefficient.PNG\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a3b25a-cfc1-491a-b3f4-ea83f2495342",
   "metadata": {},
   "source": [
    "## Conclusion and Interpretation\n",
    "\n",
    "\n",
    "<img src = \"images/table.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35889f40-d621-4b88-a294-01025254b2d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f8d44-5fde-4b92-bb10-7d45edb88f73",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Cleaning & Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e982f-21ea-4d49-bec2-5620102fbab5",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2812224-1841-4655-b00f-dde1da311ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import KernelPCA, PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7d673-1145-46dc-b7d6-2474722cc6c9",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41117807-d3fc-477e-b80d-0ed0d2d8feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in all four at once\n",
    "doctors = pd.read_csv('data/doctors.csv')\n",
    "orders = pd.read_csv('data/orders.csv')\n",
    "complaints = pd.read_csv('data/complaints.csv')\n",
    "instructions = pd.read_csv('data/instructions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6186b324-afe7-41f2-8de6-d5bc7811f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_satisfaction(sat):\n",
    "    if sat == '--':\n",
    "        sat = np.nan\n",
    "    else:\n",
    "        sat = float(sat)\n",
    "    return sat\n",
    "\n",
    "doctors['Satisfaction'] = doctors['Satisfaction'].apply(clean_satisfaction)\n",
    "\n",
    "def transform_rank(rank):\n",
    "    ###Takes name of doctor's rank and transforms it into ordinal data from 1-9\n",
    "    if rank == 'Ambassador':\n",
    "        num_rank = 9\n",
    "    elif rank == 'Titanium Plus':\n",
    "        num_rank = 8\n",
    "    elif rank == 'Titanium':\n",
    "        num_rank = 7\n",
    "    elif rank == 'Platinum Plus':\n",
    "        num_rank = 6\n",
    "    elif rank == 'Platinum':\n",
    "        num_rank = 5\n",
    "    elif rank == 'Gold Plus':\n",
    "        num_rank = 4\n",
    "    elif rank == 'Gold':\n",
    "        num_rank = 3\n",
    "    elif rank == 'Silver Plus':\n",
    "        num_rank = 2\n",
    "    elif rank == 'Silver':\n",
    "        num_rank = 1\n",
    "    else:\n",
    "        num_rank = np.nan\n",
    "    return num_rank\n",
    "\n",
    "def conv_cat_to_num(cat):\n",
    "    ###Takes category of doctor and returns 1 if specialist and 0 if GP\n",
    "    if cat == 'Specialist':\n",
    "        cat = 1\n",
    "    elif cat == 'General Practitioner':\n",
    "        cat = 0\n",
    "    else:\n",
    "        cat = np.nan\n",
    "    return cat\n",
    "\n",
    "#apply to doctors dataframe\n",
    "doctors['Rank'] = doctors['Rank'].apply(transform_rank)\n",
    "doctors['Category'] = doctors['Category'].apply(conv_cat_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faec8f87-88df-4005-8bce-b75819361744",
   "metadata": {},
   "outputs": [],
   "source": [
    "ords_per_doc = orders['DoctorID'].value_counts()\n",
    "ords_per_doc = pd.DataFrame(ords_per_doc)\n",
    "ords_per_doc.index.name = 'DoctorID'\n",
    "ords_per_doc.columns = ['Orders']\n",
    "ords_per_doc.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe1fc0ca-4ab2-4b53-85b4-07d50f812587",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_IDs = complaints['DoctorID'].unique()\n",
    "doc_IDs = list(doc_IDs)\n",
    "comp_per_doc = pd.DataFrame(doc_IDs)\n",
    "comp_per_doc.columns = ['DoctorID']\n",
    "comp_per_doc['Total Complaints'] = 0\n",
    "\n",
    "for ID in doc_IDs:\n",
    "    temp_df = complaints[complaints['DoctorID'] == ID]\n",
    "    total_comp = temp_df['Qty'].sum()\n",
    "    index = comp_per_doc.index[comp_per_doc['DoctorID'] == ID].tolist()[0]\n",
    "    comp_per_doc.iloc[index, 1] = total_comp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0a9a1a-6b2a-4a7e-baf6-dfb1114d8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instr_conv_to_number(str_in):\n",
    "    if str_in == 'Yes':\n",
    "        result = 1\n",
    "    elif str_in == 'No':\n",
    "        result = 0\n",
    "    else:\n",
    "        result = np.nan\n",
    "    return result\n",
    "\n",
    "instructions['Instructions'] = instructions['Instructions'].apply(instr_conv_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70f998ce-4908-4ea1-b338-aa751b1d7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_merged = doctors.merge(comp_per_doc, how = 'left', on = 'DoctorID')\n",
    "doc_merged = doc_merged.merge(ords_per_doc, how = 'left', on = 'DoctorID')\n",
    "doc_merged = doc_merged.merge(instructions, how = 'left', on = 'DoctorID')\n",
    "\n",
    "doc_merged = doc_merged [['DoctorID',\n",
    "                          'Satisfaction', \n",
    "                          'Category', \n",
    "                          'Incidence rate', \n",
    "                          'R rate', \n",
    "                          'Experience', \n",
    "                          'Purchases', \n",
    "                          'Total Complaints', \n",
    "                          'Orders', \n",
    "                          'Instructions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "901f25bc-7fde-4fd8-8757-93386d81fee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DoctorID</th>\n",
       "      <th>Satisfaction</th>\n",
       "      <th>Category</th>\n",
       "      <th>Incidence rate</th>\n",
       "      <th>R rate</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Purchases</th>\n",
       "      <th>Total Complaints</th>\n",
       "      <th>Orders</th>\n",
       "      <th>Instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AHDCBA</td>\n",
       "      <td>53.85</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.20</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABHAHF</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDHFJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BJJHCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.48</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FJBEA</td>\n",
       "      <td>76.79</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.75</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DoctorID  Satisfaction  Category  Incidence rate  R rate  Experience  \\\n",
       "0   AHDCBA         53.85         1            49.0    0.90        1.20   \n",
       "1   ABHAHF        100.00         0            37.0    0.00        0.00   \n",
       "2    FDHFJ           NaN         1            33.0    1.53        0.00   \n",
       "3   BJJHCA           NaN         1            28.0    2.03        0.48   \n",
       "4    FJBEA         76.79         1            23.0    0.96        0.75   \n",
       "\n",
       "   Purchases  Total Complaints  Orders  Instructions  \n",
       "0       49.0               NaN     NaN           1.0  \n",
       "1       38.0               NaN     NaN           NaN  \n",
       "2       34.0               NaN     NaN           NaN  \n",
       "3       29.0               NaN     NaN           NaN  \n",
       "4       24.0               NaN     NaN           NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367012a-85cd-4179-b217-72417fe90074",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fec93c9c-ba4c-4921-a7bb-94225f45c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = doc_merged.drop(['DoctorID', 'Instructions'], axis=1)\n",
    "df['Total Complaints'] = df['Total Complaints'].fillna(0)\n",
    "df['Orders'] = df['Orders'].fillna(0)\n",
    "df['Satisfaction'] = KNNImputer(n_neighbors=4).fit_transform(np.array(df['Satisfaction'])[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed18225-bd3c-4248-8188-aacd70b1accb",
   "metadata": {},
   "source": [
    "### Transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da233dfc-8077-47d5-b3fc-de134ab11a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, input_array, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, input_array, y=None):\n",
    "        return input_array*1\n",
    "\n",
    "scaled_pipeline = Pipeline([\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "identity_pipeline = Pipeline([\n",
    "        ('identity', IdentityTransformer()),\n",
    "    ])\n",
    "scaler = ColumnTransformer([\n",
    "        ('scaled', scaled_pipeline, [\"Satisfaction\", \"Incidence rate\", \"R rate\", \"Purchases\", \"Total Complaints\", \"Orders\"]),\n",
    "        ('identity', identity_pipeline, [\"Experience\", \"Category\"]),\n",
    "    ])  # transform columnwise and feature is on 2nd dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f151a4-56c2-4b77-9aba-180b11581fe9",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7cba106-3447-45fc-8b04-a553c8d158cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = KernelPCA(n_components=3, random_state=22, kernel='rbf')\n",
    "km = KMeans(n_clusters=3, init=\"k-means++\", n_init=50, max_iter=500, random_state=22)\n",
    "clusterer = Pipeline([\n",
    "           ('scaler', scaler),\n",
    "           ('pca', pca),\n",
    "           ('kmeans', km)])\n",
    "_ = clusterer.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b1e40c-2907-4ae8-be42-760f71bd3191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Satisfaction</th>\n",
       "      <th>Category</th>\n",
       "      <th>Incidence rate</th>\n",
       "      <th>R rate</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Purchases</th>\n",
       "      <th>Total Complaints</th>\n",
       "      <th>Orders</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.85000</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.20</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.21872</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.21872</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.48</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.79000</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.75</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Satisfaction  Category  Incidence rate  R rate  Experience  Purchases  \\\n",
       "0      53.85000         1            49.0    0.90        1.20       49.0   \n",
       "1     100.00000         0            37.0    0.00        0.00       38.0   \n",
       "2      29.21872         1            33.0    1.53        0.00       34.0   \n",
       "3      29.21872         1            28.0    2.03        0.48       29.0   \n",
       "4      76.79000         1            23.0    0.96        0.75       24.0   \n",
       "\n",
       "   Total Complaints  Orders  Cluster  \n",
       "0               0.0     0.0        0  \n",
       "1               0.0     0.0        0  \n",
       "2               0.0     0.0        0  \n",
       "3               0.0     0.0        0  \n",
       "4               0.0     0.0        0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_df = df.copy().assign(Cluster=clusterer['kmeans'].labels_)\n",
    "cluster_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
